{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# built-in\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "# third-party\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "# ours\n",
    "root = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(root)\n",
    "import plot_all_figs_helper as helper\n",
    "import configs\n",
    "import tools\n",
    "from analysis.analysis import evaluate_run\n",
    "from models.model_utils import get_model\n",
    "from datasets.recall import RecallDataset, EcstasyRecall\n",
    "\n",
    "# setup\n",
    "figpath = os.path.join(root, 'publish')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Arial',\n",
    "        font_scale=7/12., #default size is 12pt, scale down to 7pt\n",
    "        palette='Set1',\n",
    "        rc={'axes.axisbelow': True,\n",
    "            'axes.edgecolor': 'lightgrey',\n",
    "            'axes.facecolor': 'None',\n",
    "            'axes.grid': False,\n",
    "            'axes.labelcolor': 'dimgrey',\n",
    "            'axes.spines.right': False,\n",
    "            'axes.spines.top': False,\n",
    "            'text.color': 'dimgrey', #e.g. legend\n",
    "\n",
    "            'lines.solid_capstyle': 'round',\n",
    "            'legend.facecolor': 'white',\n",
    "            'legend.framealpha':0.8,\n",
    "\n",
    "            'xtick.bottom': True,\n",
    "            'xtick.color': 'dimgrey',\n",
    "            'xtick.direction': 'out',\n",
    "\n",
    "            'ytick.color': 'dimgrey',\n",
    "            'ytick.direction': 'out',\n",
    "            'ytick.left': True,\n",
    "\n",
    "             'xtick.major.size': 2,\n",
    "             'xtick.major.width': .5,\n",
    "             'xtick.minor.size': 1,\n",
    "             'xtick.minor.width': .5,\n",
    "\n",
    "             'ytick.major.size': 2,\n",
    "             'ytick.major.width': .5,\n",
    "             'ytick.minor.size': 1,\n",
    "             'ytick.minor.width': .5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Benchmark\n",
    "## (a) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecallDataset(T_min=15, T_max=15, stim_dim=30, p_recall=1)\n",
    "dataset.visualize(figpath=figpath, figname='benchmark_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Performance: simple-sequential, simple-random (p=4/N), Hopfield, TVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = 40      \n",
    "ref_configs = {'Sequential' : configs.get_config('ref_seq', stim_dim=net_size, hidden_size=net_size), \n",
    "               'Random' : configs.get_config('ref_rand', stim_dim=net_size, hidden_size=net_size),\n",
    "               'Hopfield' : configs.get_config('hopfield', stim_dim=net_size),\n",
    "              }\n",
    "\n",
    "pprint(ref_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(figpath, 'benchmark_acc_vs_seqlen.pkl')\n",
    "\n",
    "seqlen_list, acc_vs_seqlen, err_vs_seqlen = helper.get_acc_vs_seqlen_configs(ref_configs, fname=fname, repeat='auto')\n",
    "\n",
    "path = '../files/tvt/000000'\n",
    "config = tools.load_config(path)\n",
    "net = get_model(config)\n",
    "net.load(os.path.join(path, 'model.pt'))\n",
    "acc_vs_seqlen['TVT'], err_vs_seqlen['TVT'] = helper._get_acc_vs_seqlen(net, seqlen_list, config=config, repeat='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = helper.plot_acc_vs_seqlen(\n",
    "    seqlen_list, acc_vs_seqlen, err_vs_seqlen,\n",
    "    save_fname=fname[:-4]+'.pdf'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(figpath, 'benchmark_capacity_vs_size.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    sizes = result['sizes']\n",
    "    capacities = result['capacities']\n",
    "    labels = result['labels']\n",
    "    thres = result['thres']\n",
    "except:    \n",
    "    thres = 0.98\n",
    "    size_list = [20,40,80,160]\n",
    "    sizes = []\n",
    "    capacities = []\n",
    "    labels = []\n",
    "    for label, config in ref_configs.items():\n",
    "        for i, net_size in enumerate(size_list):        \n",
    "            print('{} N={}'.format(label, net_size))\n",
    "            config['dataset']['stim_dim'] = net_size\n",
    "            if 'plasticnet' in config:\n",
    "                config['plasticnet']['hidden_size'] = net_size\n",
    "            for _ in range(50): # Number of repeats\n",
    "                capacity = helper.get_capacity(config, thres=thres, repeat=1)\n",
    "                capacities.append(capacity)\n",
    "                labels.append(label)\n",
    "                sizes.append(net_size)\n",
    "    sizes = np.array(sizes)\n",
    "    capacities = np.array(capacities)\n",
    "    labels = np.array(labels)\n",
    "    result = {\n",
    "        'sizes': sizes,\n",
    "        'capacities': capacities,\n",
    "        'labels': labels,\n",
    "        'thres': thres\n",
    "        }\n",
    "    joblib.dump(result, fname)\n",
    "\n",
    "ax = helper.plot_capacity(sizes, capacities, labels, ref_configs.keys(), thres)\n",
    "\n",
    "ax.set_xlim([15,165])\n",
    "helper.format_and_save(ax.get_figure(), fname[:-4]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3: Optimization\n",
    "## (a) Optimized performance\n",
    "Note that trained has passive decay in h2o but performs about the same as active if correctly tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = 40\n",
    "prob_list = [k/net_size for k in [1,4]]\n",
    "\n",
    "exp_path = '../files/train_random_capacity'  \n",
    "\n",
    "select = {'plasticnet.hidden_size' : net_size,\n",
    "          'dataset.stim_dim' : net_size,\n",
    "          'plasticnet.local_thirdfactor.mode' : 'sequential'}\n",
    "modeldirs = tools.get_modeldirs(exp_path, select_dict=select)\n",
    "\n",
    "for p in prob_list:\n",
    "    select = {'plasticnet.hidden_size' : net_size,\n",
    "              'dataset.stim_dim' : net_size,\n",
    "              'plasticnet.local_thirdfactor.mode' : 'random',\n",
    "              'plasticnet.local_thirdfactor.b0' : p}\n",
    "    modeldirs += tools.get_modeldirs(exp_path, select_dict=select) \n",
    "\n",
    "for path in modeldirs:\n",
    "    config = tools.load_config(path)\n",
    "    try: p = config['plasticnet']['local_thirdfactor']['b0']\n",
    "    except: p = ''\n",
    "    print(path, config['plasticnet']['local_thirdfactor']['mode'], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(figpath, 'optimized_acc_vs_seqlen.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    seqlen_list = result['seqlen_list']\n",
    "    acc_vs_seqlen = result['acc_vs_seqlen']\n",
    "    err_vs_seqlen = result['err_vs_seqlen']\n",
    "except:\n",
    "    acc_vs_seqlen = {}\n",
    "    err_vs_seqlen = {}\n",
    "    seqlen_list = np.unique(np.logspace(0,np.log10(180), 50, dtype=int))\n",
    "    for path in modeldirs:    \n",
    "        for trained in [False, True]:\n",
    "            config = tools.load_config(path)\n",
    "            results = tools.load_results(path)\n",
    "            log = tools.load_log(path)\n",
    "            if trained:\n",
    "                net = get_model(config)\n",
    "                model_path = os.path.join(path, 'model.pt')\n",
    "                net.load(model_path)\n",
    "            else:\n",
    "                ref_config = tools.nested_update(config,\n",
    "                    {'plasticnet' : {'h2o' : {'decay' : 'active'},\n",
    "                                     'h2o_use_local_thirdfactor' : True, #required for active decay\n",
    "                                     'reset_to_reference': True}})\n",
    "                net = get_model(ref_config)\n",
    "            label = '{} {}'.format('Trained' if trained else 'Simple', net.rnn.ltf.mode)\n",
    "            if net.rnn.ltf.mode == 'random':\n",
    "                label += ' {}'.format(config['plasticnet']['local_thirdfactor']['b0'])\n",
    "            print(label)\n",
    "            acc_vs_seqlen[label], err_vs_seqlen[label] = helper._get_acc_vs_seqlen(\n",
    "                net, seqlen_list, config, repeat='auto'\n",
    "                )\n",
    "    result = {'seqlen_list':seqlen_list, 'acc_vs_seqlen':acc_vs_seqlen, 'err_vs_seqlen':err_vs_seqlen}\n",
    "    joblib.dump(result, fname)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "legend_handles = []\n",
    "for label, acc in acc_vs_seqlen.items():\n",
    "    #relies on the order being the same as during compute\n",
    "    err = err_vs_seqlen[label]\n",
    "    if label.startswith('Trained'): \n",
    "        color = ax.get_lines()[-1].get_color()\n",
    "        handle = ax.plot(seqlen_list, acc_vs_seqlen[label], color=color, label='Trained', ls='-')\n",
    "        ax.fill_between(\n",
    "            seqlen_list, [e[0] for e in err], [e[1] for e in err],\n",
    "            label='Trained', color=color, alpha=0.3\n",
    "            )\n",
    "    else:\n",
    "        label_legend = label[label.find(' ')+1:].capitalize()\n",
    "        handle = ax.plot(seqlen_list, acc_vs_seqlen[label], label=label_legend, ls='--')\n",
    "        ax.fill_between(\n",
    "            seqlen_list, [e[0] for e in err], [e[1] for e in err],\n",
    "            label=label_legend, alpha=0.3\n",
    "            )\n",
    "    legend_handles.append(handle[0])\n",
    "ax.legend(handles=legend_handles)\n",
    "ax.set_xlabel('Number of stimuli')\n",
    "ax.set_ylabel('Accuracy')\n",
    "fig.set_size_inches(2.75,1.7)\n",
    "fig.tight_layout()\n",
    "fig.savefig(fname[:-4]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Optimized capacity\n",
    "Note that scaling p with N rather than keeping constant is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = [20, 40, 80, 160]\n",
    "k = 4  #ltf_prob = k/N\n",
    "\n",
    "exp_path = '../files/train_random_capacity'  \n",
    "modeldirs_dict = defaultdict(list)\n",
    "             \n",
    "for trial in os.listdir(exp_path):\n",
    "    path = os.path.join(exp_path, trial)\n",
    "    config = tools.load_config(path)\n",
    "    \n",
    "    if config['plasticnet']['local_thirdfactor']['mode'] == 'sequential':\n",
    "        modeldirs_dict['Sequential'].append(path)\n",
    "        \n",
    "    size = config['plasticnet']['hidden_size']\n",
    "    if (config['plasticnet']['local_thirdfactor']['mode'] == 'random'\n",
    "    and config['plasticnet']['local_thirdfactor']['b0'] == k/size):\n",
    "        modeldirs_dict['Random {}/N'.format(k)].append(path)\n",
    "\n",
    "    if (config['plasticnet']['local_thirdfactor']['mode'] == 'random'\n",
    "    and config['plasticnet']['local_thirdfactor']['b0'] == 0.1):\n",
    "        modeldirs_dict['Random 0.1'].append(path)\n",
    "    \n",
    "for label, modeldirs in modeldirs_dict.items():\n",
    "    for path in modeldirs:\n",
    "        config = tools.load_config(path)\n",
    "        try: p = config['plasticnet']['local_thirdfactor']['b0']\n",
    "        except: p = ''\n",
    "        print(label, path, config['plasticnet']['local_thirdfactor']['mode'], p, config['plasticnet']['hidden_size'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(figpath, 'optimized_capacity_vs_size.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    sizes = result['sizes']\n",
    "    capacities = result['capacities']\n",
    "    labels = result['labels']\n",
    "    thres = result['thres']\n",
    "except: \n",
    "    thres = 0.98\n",
    "    sizes = []\n",
    "    capacities = []\n",
    "    labels = []\n",
    "\n",
    "    for label, modeldirs in modeldirs_dict.items():\n",
    "        for path in modeldirs:\n",
    "            config = tools.load_config(path)\n",
    "            net = get_model(config)\n",
    "            model_path = os.path.join(path, 'model.pt')\n",
    "            net.load(model_path)\n",
    "            print(label, config['plasticnet']['hidden_size'])\n",
    "#             i = int(np.log2(net.rnn.hidden_size/10))-1 #assumes size_list=[20,40,80,160]\n",
    "#             capacity_vs_size[label][i] = helper.get_capacity(config, net, thres=thres, repeat=50)\n",
    "            for _ in range(50): # Number of repeats\n",
    "                capacity = helper.get_capacity(config, net, thres=thres, repeat=1)\n",
    "                capacities.append(capacity)\n",
    "                labels.append(label)\n",
    "                sizes.append(net.rnn.hidden_size)\n",
    "    sizes = np.array(sizes)\n",
    "    capacities = np.array(capacities)\n",
    "    labels = np.array(labels)\n",
    "    result = {\n",
    "        'sizes': sizes,\n",
    "        'capacities': capacities,\n",
    "        'labels': labels,\n",
    "        'thres': thres\n",
    "        }\n",
    "    joblib.dump(result, fname)\n",
    "\n",
    "ax = helper.plot_capacity(sizes, capacities, labels, ['Sequential', 'Random 4/N', 'Random 0.1'], thres)\n",
    "ax.set_xlim([15,165])\n",
    "helper.format_and_save(ax.get_figure(), fname[:-4]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Training loss/accuracy: trained-seq, trained-rand 4/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = 40\n",
    "\n",
    "exp_path = '../files/train_prepost_zero_init'  \n",
    "\n",
    "modeldirs = []\n",
    "modeldirs += tools.get_modeldirs(exp_path, select_dict=\n",
    "                                {'plasticnet.hidden_size' : net_size,\n",
    "                                 'dataset.stim_dim' : net_size,\n",
    "                                 'plasticnet.local_thirdfactor.mode' : 'sequential'})\n",
    "modeldirs += tools.get_modeldirs(exp_path, select_dict=\n",
    "                                 {'plasticnet.hidden_size' : net_size,\n",
    "                                  'dataset.stim_dim' : net_size,\n",
    "                                  'plasticnet.local_thirdfactor.mode' : 'random',\n",
    "                                  'plasticnet.local_thirdfactor.b0' : 0.1}) \n",
    "\n",
    "for path in modeldirs:\n",
    "    config = tools.load_config(path)\n",
    "    try: p = config['plasticnet']['local_thirdfactor']['b0']\n",
    "    except: p = ''\n",
    "    print(path, config['plasticnet']['local_thirdfactor']['mode'], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,sharex=True)\n",
    "clip=60\n",
    "for path in modeldirs:    \n",
    "    log = tools.load_log(path)\n",
    "    \n",
    "    config = tools.load_config(path)\n",
    "    label = config['plasticnet']['local_thirdfactor']['mode'].capitalize()\n",
    "    \n",
    "    ax[0].plot(log['steps'][:clip],log['loss_train'][:clip], label=label)\n",
    "    ax[1].plot(log['steps'][:clip],log['acc_train'][:clip], label=label)\n",
    "ax[0].legend()    \n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Iterations')\n",
    "\n",
    "fname = os.path.join(figpath, 'loss_acc_optimized.pdf')\n",
    "fig.set_size_inches(2,3.5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Training plasticity params: trained-seq, trained-rand 4/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "for path in modeldirs: \n",
    "    fig, ax = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "    log = tools.load_log(path)\n",
    "    config = tools.load_config(path)\n",
    "    label = config['plasticnet']['local_thirdfactor']['mode']\n",
    "    \n",
    "    iters = log['steps'][clip]\n",
    "    N = len(log['steps'][:clip])\n",
    "    for c, layer in enumerate(['i2h', 'h2o']):\n",
    "        for r, syn in enumerate(['pre', 'post']):\n",
    "            ax[r,c].axvline(0, color='grey', linewidth=1)\n",
    "            ax[r,c].axhline(0, color='grey', linewidth=1)\n",
    "            \n",
    "            w = log['rnn.{}.{}_fn.weight'.format(layer, syn)][:clip]\n",
    "            b = log['rnn.{}.{}_fn.bias'.format(layer, syn)][:clip]\n",
    "            for i in range(N-1):\n",
    "                ax[r,c].plot(w[i:i+2], b[i:i+2], color=plt.cm.jet(i/N))\n",
    "            \n",
    "            layer_str = 'Input-to-hidden' if layer == 'i2h' else 'Hidden-to-output'\n",
    "            title = '{}, {}-synaptic'.format(layer_str, syn)    \n",
    "            ax[r,c].set_title(title)\n",
    "\n",
    "\n",
    "    cb = fig.colorbar(plt.cm.ScalarMappable(norm=mpl.colors.Normalize(0, iters),\n",
    "                                       cmap=plt.cm.jet),\n",
    "                 ax=ax, fraction=0.05, aspect=40, ticks=[0,iters]          \n",
    "                 )\n",
    "    cb.set_label('Iterations', labelpad=-15)\n",
    "    [a.set_xlabel('$\\widetilde{a}$') for a in ax[1,:].flatten()]\n",
    "    [a.set_ylabel('$\\widetilde{b}$') for a in ax[:,0].flatten()]\n",
    "\n",
    "    fname = os.path.join(figpath, 'plast_params_{}.pdf'.format(label))\n",
    "    fig.set_size_inches(4,3.5)\n",
    "#     fig.tight_layout()\n",
    "    fig.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4: Harder tasks\n",
    "## (a) Continual recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecallDataset(T_min=15, T_max=15, stim_dim=30, p_recall=0.6,\n",
    "                        recall_order='interleave', recall_interleave_delay=2)\n",
    "dataset.visualize(figpath=figpath, figname='continual_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continual performance: simple-seq, simple/trained-rand (p=4/N), Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = 40      \n",
    "continual_configs = {'Sequential' : configs.get_config('ref_seq', stim_dim=net_size, hidden_size=net_size), \n",
    "              'Random' : configs.get_config('ref_rand', stim_dim=net_size, hidden_size=net_size),\n",
    "              'Hopfield' : configs.get_config('hopfield', stim_dim=net_size),\n",
    "              }\n",
    "\n",
    "#from Parisi 1986\n",
    "# continual_configs['Hopfield']['hopfield']['clamp_val'] = 0.4\n",
    "# continual_configs['Hopfield']['hopfield']['learning_rate'] = 1/np.sqrt(net_size)\n",
    "# continual_configs['Hopfield']['hopfield']['steps'] = 20\n",
    "\n",
    "for key in continual_configs.keys():\n",
    "    config = continual_configs[key]\n",
    "    config['dataset']['recall_order'] = 'interleave'\n",
    "#     config['dataset']['recall_interleave_delay'] = delay\n",
    "#     config['dataset']['T_min'] = config['dataset']['T_max'] = max(1000, delay*20)\n",
    "    config['dataset']['p_recall'] = 0.5\n",
    "continual_configs['Hopfield']['hopfield']['decay_rate'] = 0.95\n",
    "\n",
    "pprint(continual_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(figpath, 'continual_acc_vs_delay.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    delay_list = result['delay_list']\n",
    "    acc_vs_delay = result['acc_vs_delay']\n",
    "    err_vs_delay = result['err_vs_delay']\n",
    "except:\n",
    "    delay_list = np.unique(np.logspace(0, np.log10(180), 50, dtype=int))\n",
    "    acc_vs_delay = defaultdict(list)\n",
    "    err_vs_delay = defaultdict(list)\n",
    "    for label, config in continual_configs.items():\n",
    "        print(label)\n",
    "        for delay in delay_list:\n",
    "            config['dataset']['recall_interleave_delay'] = delay\n",
    "            config['dataset']['T_min'] = config['dataset']['T_max'] = max(1000, delay*20)\n",
    "            net = get_model(config) \n",
    "            result = evaluate_run(model=net, update_config=config, n_batch=3)\n",
    "            acc, err = helper.get_avg_recall_acc(result)\n",
    "            print(' Delay = {}, acc = {}'.format(delay, acc))\n",
    "            acc_vs_delay[label].append(acc)\n",
    "            err_vs_delay[label].append(err)\n",
    "    result = {\n",
    "        'delay_list':delay_list, 'acc_vs_delay':acc_vs_delay,\n",
    "        'err_vs_delay':err_vs_delay\n",
    "        }\n",
    "    joblib.dump(result, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../files/train_continual'\n",
    "config = tools.load_config(path)\n",
    "net = get_model(config)\n",
    "model_path = os.path.join(path, 'model.pt')\n",
    "net.load(model_path)\n",
    "label='Trained'\n",
    "for delay in delay_list: \n",
    "    config['dataset']['recall_interleave_delay'] = delay\n",
    "    config['dataset']['T_min'] = config['dataset']['T_max'] = max(1000, delay*20)\n",
    "    result = evaluate_run(model=net, update_config=config, n_batch=3)\n",
    "    acc, err = helper.get_avg_recall_acc(result)\n",
    "    print(' Delay = {}, acc = {}'.format(delay, acc))\n",
    "    acc_vs_delay[label].append(acc)\n",
    "    err_vs_delay[label].append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = helper.plot_acc_vs_seqlen(delay_list, acc_vs_delay, err_vs_delay, \n",
    "                                   labels=['Sequential','Random','Trained','Hopfield'])\n",
    "ax.set_xlabel('Delay interval')\n",
    "ax.set_title('Continual recall', fontdict={'fontweight':'bold'})\n",
    "helper.format_and_save(ax.get_figure(), fname[:-4]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Flashbulb: simple-seq, simple/trained-rand (p=4/N), Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EcstasyRecall(T_min=15, T_max=15, stim_dim=30, p_recall=0.5,\n",
    "                        recall_order='interleave', recall_interleave_delay=5,\n",
    "                        ec_strength=3, p_ec=0.4)\n",
    "dataset.visualize(figpath=figpath, figname='flashbulb_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_flashbulb(net_type, net_title, add_legend=True, ax=None):\n",
    "    fname = os.path.join(figpath, f'flashbulb_{net_type.lower()}.pkl')\n",
    "    try:\n",
    "        result = joblib.load(fname)\n",
    "        print(\"Loaded pickle file\")\n",
    "    except:\n",
    "        vary_ec_strength = True if net_type == 'Hopfield' else False\n",
    "        result = helper.get_flashbulb_performance(\n",
    "            net_type, vary_ec_strength=vary_ec_strength\n",
    "            )\n",
    "        joblib.dump(result, fname)\n",
    "        print(\"Ran results and saved to pickle file\")\n",
    "\n",
    "    ec_strength_list = result['ec_strength_list']\n",
    "    R_list = result['R_list']\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    if len(ec_strength_list) == 1:\n",
    "        cmap_space = [0.99]\n",
    "    else:\n",
    "        cmap_space = np.linspace(0.5, 0.99, len(ec_strength_list))\n",
    "    colors_reg = [cm.Blues(i) for i in cmap_space]\n",
    "    colors_flashbulb = [cm.Reds(i) for i in cmap_space]\n",
    "\n",
    "    for ec_idx, ec_strength in enumerate(ec_strength_list):\n",
    "        if ec_strength == ec_strength_list[-1]:\n",
    "            reg_label = 'Regular'\n",
    "            flashbulb_label = 'Flashbulb'\n",
    "        else:\n",
    "            reg_label = flashbulb_label = None\n",
    "        \n",
    "        ax.plot(R_list, result[ec_strength]['acc_vs_R_reg'], \n",
    "                color=colors_reg[ec_idx], label=reg_label)\n",
    "        ax.fill_between(R_list, *zip(*result[ec_strength]['err_vs_R_reg']), \n",
    "                        color=colors_reg[ec_idx], alpha=0.3)\n",
    "        \n",
    "        ax.plot(R_list, result[ec_strength]['acc_vs_R_flashbulb'], \n",
    "                color=colors_flashbulb[ec_idx], label=flashbulb_label)\n",
    "        ax.fill_between(R_list, *zip(*result[ec_strength]['err_vs_R_flashbulb']), \n",
    "                        color=colors_flashbulb[ec_idx], alpha=0.3)\n",
    "   \n",
    "    if add_legend:\n",
    "        ax.legend()\n",
    "        ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Delay interval')\n",
    "    ax.set_title(f\"{net_title}\", fontdict={'fontweight':'bold'})\n",
    "    ax.set_ylim(0.55, 1.025)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, sharex=True, sharey=True)\n",
    "plot_flashbulb(\"Reference\", \"Flashbulb: Sequential\", ax=ax[0] )\n",
    "plot_flashbulb(\"Random\", \"Random\", add_legend=False, ax=ax[1]) # This is random reference!\n",
    "plot_flashbulb(\"Hopfield\", \"Hopfield\", add_legend=False, ax=ax[2])\n",
    "fig.set_size_inches(5.5, 1.7)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(figpath,'flashbulb_all.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Correlated: simple-seq, simple/trained-rand (p=4/N), Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecallDataset(T_min=15, T_max=15, stim_dim=30, p_recall=1,\n",
    "                        temporal_corr=0.6, temporal_corr_mode='template',\n",
    "                        )\n",
    "dataset.visualize(figpath=figpath, figname='corr_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_size = 40\n",
    "for i,corr in enumerate([0.3, 0.6, 0.9]):\n",
    "    corr_configs = {'Sequential' : configs.get_config('ref_seq', stim_dim=net_size, hidden_size=net_size),\n",
    "                   'Random' : configs.get_config('ref_rand', stim_dim=net_size, hidden_size=net_size),\n",
    "                   'Hopfield' : configs.get_config('hopfield', stim_dim=net_size),\n",
    "                  }\n",
    "\n",
    "    for label,config in corr_configs.items():\n",
    "        config['dataset']['temporal_corr']= corr\n",
    "        config['dataset']['temporal_corr_mode']= 'template'\n",
    "#     pprint(corr_configs)\n",
    "\n",
    "    fname = os.path.join(figpath, 'corr_{}_acc_vs_seqlen.pkl'.format(corr))\n",
    "    seqlen_list, acc_vs_seqlen, err_vs_seqlen \\\n",
    "        = helper.get_acc_vs_seqlen_configs(corr_configs, repeat='auto', fname=fname)\n",
    "    \n",
    "    path = '../files/train_corr/{:06d}'.format(i)\n",
    "    config = tools.load_config(path)\n",
    "    net = get_model(config)\n",
    "    net.load(os.path.join(path, 'model.pt'))\n",
    "    label = 'Trained'\n",
    "    print(label)\n",
    "    acc_vs_seqlen[label], err_vs_seqlen[label] = \\\n",
    "        helper._get_acc_vs_seqlen(net, seqlen_list, config=config, repeat='auto')\n",
    "\n",
    "    ax = helper.plot_acc_vs_seqlen(seqlen_list, acc_vs_seqlen, err_vs_seqlen, \n",
    "                                   labels=['Sequential','Random','Trained','Hopfield'])\n",
    "    ax.set_title('Correlation={}'.format(corr), fontdict={'fontweight':'bold'})\n",
    "\n",
    "    helper.format_and_save(ax.get_figure(), fname[:-4]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5: Heteroassociative tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're recomputing results, make sure this is correct for your system!!!\n",
    "filesdir = root / Path(\"files\")\n",
    "print(filesdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Heteroassociative Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecallDataset(T_min=15, T_max=15, stim_dim=30, p_recall=1,\n",
    "                       heteroassociative=True, heteroassociative_stim_dim=15)\n",
    "dataset.visualize(figsize_scalings=[[1,1], [1,0.5], [1,0.5]],\n",
    "                  figpath=figpath, figname='heteroassociative_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    'heteroassociative',\n",
    "    'heteroassociative_random_reference',\n",
    "    'heteroassociative_random',\n",
    "    'heteroassociative_hopfield'\n",
    "    ]\n",
    "exp_labels = [\n",
    "    'Sequential', 'Random',\n",
    "    'Trained', 'BAM'\n",
    "    ]\n",
    "seqlen_list = np.arange(0, 90, 5)\n",
    "seqlen_list[0] = 1\n",
    "\n",
    "fname = os.path.join(figpath, 'heteroassociative_recall.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    print(\"Loaded pickle file\")\n",
    "except:\n",
    "    result = {}\n",
    "    result['acc'] = {}\n",
    "    result['err'] = {}\n",
    "    for exp, label in zip(exps, exp_labels):\n",
    "        net = helper.load_model(exp, filesdir=filesdir)\n",
    "        fullconfig, _, _ = getattr(experiments, exp)()\n",
    "        acc_vs_seqlen, err_vs_seqlen = helper._get_acc_vs_seqlen(\n",
    "            net, seqlen_list, config=fullconfig\n",
    "            )\n",
    "        result['acc'][exp] = acc_vs_seqlen\n",
    "        result['err'][exp] = err_vs_seqlen\n",
    "    joblib.dump(result, fname)\n",
    "    print(\"Ran results and saved to pickle file\")    \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "legend_handles = []\n",
    "for exp, label in zip(exps, exp_labels):\n",
    "    acc_vs_seqlen = result['acc'][exp]\n",
    "    err_vs_seqlen = result['err'][exp]\n",
    "    handle = ax.plot(seqlen_list, acc_vs_seqlen, label=label)\n",
    "    ax.fill_between(seqlen_list, *zip(*err_vs_seqlen), label=label, alpha=0.3)\n",
    "    legend_handles.append(handle[0])\n",
    "\n",
    "ax.legend(handles=legend_handles)\n",
    "ax.set_xlabel('Number of stimuli')\n",
    "ax.set_ylabel('Accuracy')\n",
    "fig.set_size_inches(5.5/3,1.7)\n",
    "plt.title(\"Heteroassociative Recall\", fontdict={'fontweight':'bold'})\n",
    "fig.tight_layout()\n",
    "fig.savefig(fname[:-4]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Sequence Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "dataset = helper.load_dataset('seqrecall')\n",
    "dataset.visualize(figpath=figpath,figname='seqrecall_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    'seqrecall', 'seqrecall_random_reference',\n",
    "    'seqrecall_random', 'seqrecall_hopfield'\n",
    "    ]\n",
    "exp_labels = [\n",
    "    'Sequential', 'Random',\n",
    "    'Trained', 'BAM'\n",
    "    ]\n",
    "dset_param = 'n_patterns'\n",
    "dset_param_range = np.arange(0, 61, 5)\n",
    "dset_param_range[0] = 2\n",
    "\n",
    "fname = os.path.join(figpath, 'seqrecall.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    print(\"Loaded pickle file\")\n",
    "except:\n",
    "    result = helper.get_generalization_curves(\n",
    "        exps, dset_param, dset_param_range,\n",
    "        num_iters=40, filesdir=filesdir\n",
    "        )\n",
    "    joblib.dump(result, fname)\n",
    "    print(\"Ran results and saved to pickle file\")    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for exp, label in zip(exps, exp_labels):\n",
    "    x_range = result[exp]['params']\n",
    "    accs = result[exp]['accs']\n",
    "    errs = result[exp]['errs']\n",
    "    ax.plot(x_range, accs, linewidth=1, label=label)\n",
    "    ax.fill_between(\n",
    "        x_range,\n",
    "        [e[0] for e in errs], [e[1] for e in errs],\n",
    "        label=label, alpha=0.3\n",
    "        )\n",
    "\n",
    "ax.set_xlabel('Number of patterns')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.title(\"Sequence Recall\", fontdict={'fontweight':'bold'})\n",
    "fig.set_size_inches(5.5/3,1.7)\n",
    "fig.tight_layout()\n",
    "fig.savefig(fname[:-4]+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Copy-Paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "dataset = helper.load_dataset('copy')\n",
    "dataset.visualize(figpath=figpath, figname='copy_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    'copy', 'copy_random_reference',\n",
    "    'copy_random', 'copy_hopfield'\n",
    "    ]\n",
    "exp_labels = [\n",
    "    'Sequential', 'Random',\n",
    "    'Trained', 'BAM'\n",
    "    ]\n",
    "dset_param = 'n_patterns'\n",
    "dset_param_range = np.arange(1,21)\n",
    "\n",
    "fname = os.path.join(figpath, 'copy.pkl')\n",
    "try:\n",
    "    result = joblib.load(fname)\n",
    "    print(\"Loaded pickle file\")\n",
    "except:\n",
    "    result = helper.get_generalization_curves(\n",
    "        exps, dset_param, dset_param_range,\n",
    "        num_iters=40, filesdir=filesdir\n",
    "        )\n",
    "    joblib.dump(result, fname)\n",
    "    print(\"Ran results and saved to pickle file\")    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for exp, label in zip(exps, exp_labels):\n",
    "    params = result[exp]['params']\n",
    "    accs = result[exp]['accs']\n",
    "    errs = result[exp]['errs']\n",
    "    ax.plot(params, accs, linewidth=1, label=label)\n",
    "    ax.fill_between(\n",
    "        params,\n",
    "        [e[0] for e in errs], [e[1] for e in errs],\n",
    "        label=label, alpha=0.3\n",
    "        )\n",
    "\n",
    "ax.set_xlabel('Number of patterns')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.axvline(10, color=\"gray\", linestyle=\"dashed\") # Maximum seen in training\n",
    "fig.set_size_inches(5.5/3,1.7)\n",
    "plt.title(\"Copy-Paste\", fontdict={'fontweight':'bold'})\n",
    "plt.tight_layout()\n",
    "fig.savefig(fname[:-4]+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
